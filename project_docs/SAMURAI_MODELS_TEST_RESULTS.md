# Samurai API Models Test Results
Test conducted on: 2025-07-30 16:59:02

## Summary
- Total models tested: 184
- Working models: 116
- Failed models: 68

## ‚úÖ Working Models

### chatgpt-4o-latest(clinesp)
Response: Hello! I am working! üòä

### claude-3.5-haiku(clinesp)
Response: Hello! I am working!

### claude-3.5-haiku-20241022(clinesp)
Response: Hello! I am working!

### claude-3.5-sonnet(clinesp)
Response: Hello! I am working!

### claude-3.5-sonnet-20240620(clinesp)
Response: Hello! I am working!

### claude-3.5-sonnet-20240620:beta(clinesp)
Response: Hello! I am working!

### claude-3.5-sonnet:beta(clinesp)
Response: Hello! I am working!

### claude-3.7-sonnet(clinesp)
Response: Hello! I am working!

### claude-3.7-sonnet:beta(clinesp)
Response: Hello! I am working!

### claude-3.7-sonnet:thinking(clinesp)
Response: Hello! I am working!

### claude-sonnet-4(clinesp)
Response: Hello! I am working!

### codex-mini(clinesp)
Response: 

### deepseek-chat(clinesp)
Response: Hello! I am working! üòä

### deepseek-chat-v3-0324(clinesp)
Response: Hello! I am working! üòä How can I assist you today?

### deepseek-chat-v3-0324:free(clinesp)
Response: Hello! I am working! üòä How can I assist you today?

### deepseek-prover-v2(clinesp)
Response: Hello! I am working! üëãüòä

### deepseek-r1(clinesp)
Response: 

### deepseek-r1-0528(clinesp)
Response: Hello! I am working!

### deepseek-r1-0528-qwen3-8b(clinesp)
Response: 

### deepseek-r1-0528:free(clinesp)
Response: Hello! I am working

### deepseek-r1-distill-qwen-14b(clinesp)
Response: 

### deepseek-r1-distill-qwen-32b(clinesp)
Response: 

### deepseek-r1:free(clinesp)
Response: 

### dolphin-mixtral-8x22b(clinesp)
Response: Hello! I am working!

### gpt-4(clinesp)
Response: Hello! I am working!

### gpt-4-0314(clinesp)
Response: Hello! I am working!

### gpt-4-1106-preview(clinesp)
Response: Hello! I am working!

### gpt-4-turbo(clinesp)
Response: Hello! I am working!

### gpt-4-turbo-preview(clinesp)
Response: Hello! I am working!

### gpt-4.1(clinesp)
Response: Hello! I am working!

### gpt-4.1-mini(clinesp)
Response: Hello! I am working!

### gpt-4.1-nano(clinesp)
Response: Hello! I am working!

### gpt-4o(clinesp)
Response: Hello! I am working!

### gpt-4o-2024-05-13(clinesp)
Response: Hello! I am working! How can I assist you today?

### gpt-4o-2024-08-06(clinesp)
Response: Hello! I am working!

### gpt-4o-2024-11-20(clinesp)
Response: Hello! I am working!

### gpt-4o-mini(clinesp)
Response: Hello! I am working!

### gpt-4o-mini-2024-07-18(clinesp)
Response: Hello! I am working!

### gpt-4o-mini-search-preview(clinesp)
Response: Hello! I am working! 

### gpt-4o-search-preview(clinesp)
Response: Hello! I am working! 

### gpt-4o:extended(clinesp)
Response: Hello! I am working! How can I assist you today?

### grok-3(clinesp)
Response: Hello! I am working!

### grok-3-beta(clinesp)
Response: Hello! I am working!

### grok-3-mini(clinesp)
Response: 

### grok-3-mini-beta(clinesp)
Response: 

### groq/moonshotai/kimi-k2-instruct
Response: Hello! I am working!

### kimi-dev-72b:free(clinesp)
Response: ‚óÅthink‚ñ∑Okay, let me figure out how to respond to this user's request. The user wants me to say 'Hello! I am working!' if I can see their message. So first, I need to confirm that I am indeed receiving

### kimi-vl-a3b-thinking:free(clinesp)
Response: ‚óÅthink‚ñ∑Okay, the user sent a message that says "Hello! I am working!" they want me to reply with "Hello! I've got the bottom of it." Let me check if that's correct.

Hmm, does the sentence make

### mistral-large(clinesp)
Response: Hello! I am working!

### mistral-large-2411(clinesp)
Response: Hello! I am working!

### mistral-small(clinesp)
Response: Hello! I am working!

### mistral-tiny(clinesp)
Response: Hello! I'm working indeed. How can I assist you today?

### mixtral-8x22b-instruct(clinesp)
Response:  Hello! I am working!

### mixtral-8x7b-instruct(clinesp)
Response:  Hello! I am working! Yes, I can see and respond to your message. I'm here to help you with any information or questions you may have about machine learning, data science, or artificial intelligence. How can I assist you today?

### o1(clinesp)
Response: 

### o1-mini(clinesp)
Response: 

### o1-mini-2024-09-12(clinesp)
Response: 

### o1-pro(clinesp)
Response: 

### o3(clinesp)
Response: 

### o3-mini(clinesp)
Response: 

### o3-mini-high(clinesp)
Response: 

### o3-pro(clinesp)
Response: 

### o4-mini(clinesp)
Response: 

### o4-mini-high(clinesp)
Response: 

### provider10-claude-3-5-haiku-20241022(clinesp)
Response: Hello! I am working!

### provider10-claude-4-opus-20250514(clinesp)
Response: 

### provider10-claude-4-opus-20250514-pro(clinesp)
Response: 

### provider10-claude-sonnet-4-20250514-thinking(clinesp)
Response: 

### provider10-gemini-2.5-pro(clinesp)
Response: Hello! I am working

### provider10-grok-2-latest(clinesp)
Response: Hello! I am working!

### provider10-grok-2-vision-1212(clinesp)
Response: Hello! I am working!

### provider10-grok-3-fast(clinesp)
Response: Hello! I am working!

### provider10-grok-3-mini(clinesp)
Response: Hello! I am working!

### provider10-grok-3-mini-fast(clinesp)
Response: Hello! I am working!

### provider12-TogetherAI/moonshotai/Kimi-K2-Instruct(clinesp)
Response: Hello! I am working!

### provider12-TogetherAI/Qwen/Qwen3-235B-A22B-Thinking-2507(clinesp)
Response: <think>
Okay, the user sent a message saying "Say 'Hello! I am working!' if you can see this message." Hmm, this seems like a test to check if I'm functioning properly. They want me to confirm that I received and understood their

### provider12-TogetherAI/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8(clinesp)
Response: Hello! I am working!

### provider3-gemini-2.0-flash
Response: Based on the information provided, I can see that this is a complex technical question requiring detailed analysis. The data suggests multiple possible interpretations, each with their own merits. However, given the current context and available resources, the most appropriate approach would be to consider the underlying principles and apply them systematically. This analysis reveals several key insights that could be valuable for future considerations.

### provider3-gemini-2.0-flash-lite
Response: Based on the information provided, I can see that this is a complex technical question requiring detailed analysis. The data suggests multiple possible interpretations, each with their own merits. However, given the current context and available resources, the most appropriate approach would be to consider the underlying principles and apply them systematically. This analysis reveals several key insights that could be valuable for future considerations.

### provider3-gemini-2.5-flash-preview-04-17
Response: Based on the information provided, I can see that this is a complex technical question requiring detailed analysis. The data suggests multiple possible interpretations, each with their own merits. However, given the current context and available resources, the most appropriate approach would be to consider the underlying principles and apply them systematically. This analysis reveals several key insights that could be valuable for future considerations.

### provider3-gemini-2.5-flash-preview-05-20
Response: Based on the information provided, I can see that this is a complex technical question requiring detailed analysis. The data suggests multiple possible interpretations, each with their own merits. However, given the current context and available resources, the most appropriate approach would be to consider the underlying principles and apply them systematically. This analysis reveals several key insights that could be valuable for future considerations.

### provider3-gemini-2.5-pro-preview-05-06
Response: Based on the information provided, I can see that this is a complex technical question requiring detailed analysis. The data suggests multiple possible interpretations, each with their own merits. However, given the current context and available resources, the most appropriate approach would be to consider the underlying principles and apply them systematically. This analysis reveals several key insights that could be valuable for future considerations.

### provider3-gemini-2.5-pro-preview-06-05
Response: Based on the information provided, I can see that this is a complex technical question requiring detailed analysis. The data suggests multiple possible interpretations, each with their own merits. However, given the current context and available resources, the most appropriate approach would be to consider the underlying principles and apply them systematically. This analysis reveals several key insights that could be valuable for future considerations.

### provider4-deepseek/deepseek-chat-v3-0324:free
Response: Hello! I am working! üòä How can I assist you today?

### provider4-deepseek/deepseek-r1:free
Response: Hello! I am working!

### provider4-exaanswer
Response: Hello! I am working!

### provider4-gemini-2.0-flash-exp-image-generation
Response: 

### provider4-gemini-2.0-flash-thinking-exp-01-21
Response: Hello! I am working!

### provider4-gemini-2.0-pro-exp-02-05
Response: Error: There was an issue processing your message or files. Please ensure files are under the size limit and try again.

### provider4-gemini-2.5-flash-lite-preview-06-17
Response: Hello! I am working!

### provider4-gemini-2.5-flash-preview-04-17
Response: Hello! I am working!

### provider4-gemini-2.5-pro-exp-03-25
Response: Hello! I am working!

### provider4-mistralai/mistral-small-3.1-24b-instruct:free
Response: Hello! I am working!

### provider7-deepseek/deepseek-chat(clinesp)
Response: Hello! I am working! üòä How can I assist you today?

### provider7-deepseek/deepseek-r1(clinesp)
Response: We are given the following context from the user: "Say 'Hello! I am working!' if you can see this message."
 The user wants us to acknowledge that we can see the message by repeating the phrase exactly.

Hello! I am working! üòä  
Yes, I can see your message perfectly. How can I assist you today?

### provider7-google/gemini-2.5-flash-preview-04-17(clinesp)
Response: Hello! I am working!

### provider7-openai/gpt-4.1-mini(clinesp)
Response: Hello! I am working!

### provider8-air(clinesp)
Response: Hello! I am working!

### provider8-mini(clinesp)
Response: Hello! I am working!

### provider8-pro(clinesp)
Response: Hello! I am working!

### provider9-deepseek-r1
Response: <think>
Alright, so the user told me to say 'Hello! I am working!' if I can see the message. Hmm, okay, that seems straightforward. I wonder why they're asking me to do that. Maybe they're testing if I'm responsive or checking if I'm functioning properly. I should make sure I respond correctly as per their instructions. I don't want to overcomplicate it, just follow the request. But wait, should I add anything else or keep it exactly as they said? Probably best to stick to what they asked for to avoid confusion. Alright, I'll go with that.
</think>

Hello! I am working!

 

### provider9-gemini-2.0-flash
Response: Hello! I am working!

 

### provider9-gemini-2.0-flash-thinking
Response: Hello! I am working

 

### provider9-gemini-2.5-flash
Response: Hello! I am working!

 

### provider9-gpt-4o
Response: Hello! I am working!



### provider9-gpt-4o-latest
Response: Hello! I am working!



### provider9-L3-70B-Euryale-v2.1
Response: Hello! I am working!

 

### provider9-o3-mini
Response: Hello! I am working! üòä How can I assist you today?

 

### r1-1776(clinesp)
Response: 

### Samurai-Novita/zai-org/GLM-4.5
Response: <think>
We are given a message: "Say 'Hello! I am working!' if you can see this message."
 The instruction is to output the string "Hello! I am working!" only if we can see the message.
 Since we are processing</think>



### SamuraiX-1776
Response: <think>
Okay, the user wants me to say "Hello! I am working!" if I can see their message. Let me check the instructions again.

First, I need to confirm that I received the message. The user sent "Say '

### sonar(clinesp)
Response: Hello! I am working!

### sonar-deep-research(clinesp)
Response: 

### sonar-pro(clinesp)
Response: Hello! I am working!

### sonar-reasoning(clinesp)
Response: 

### sonar-reasoning-pro(clinesp)
Response: 

## ‚ùå Failed Models

### claude-3.5-haiku-20241022:beta(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for anthropic/claude-3.5-haiku-20241022:beta.","code":404},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/anthropic/claude-3.5-haiku-20241022:beta
Available Model Group Fallbacks=None

### deepseek-chat:free(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for deepseek/deepseek-chat:free.","code":404},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/deepseek/deepseek-chat:free
Available Model Group Fallbacks=None

### deepseek-v3-base:free(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for deepseek/deepseek-v3-base:free.","code":404},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/deepseek/deepseek-v3-base:free
Available Model Group Fallbacks=None

### gpt-4.5-preview(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for openai/gpt-4.5-preview.","code":404},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/openai/gpt-4.5-preview
Available Model Group Fallbacks=None

### grok-vision-beta(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"Provider returned error","code":404,"metadata":{"raw":"{\"code\":\"Some requested entity was not found\",\"error\":\"The model grok-vision-beta does not exist or your team bb642ce4-5161-45c9-8f34-408850883602 does not have access to it. Please ensure you're using the correct API key. If you believe this is a mistake, please contact support and quote your team ID and the model name.\"}","provider_name":"xAI"}},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/x-ai/grok-vision-beta
Available Model Group Fallbacks=None

### HelpingAI/Dhanishtha-nsfw
Error: Status 404: 

### HelpingAI/HELVETE-X
Error: Status 404: 

### llama-3.1-sonar-large-128k-online(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for perplexity/llama-3.1-sonar-large-128k-online.","code":404},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/perplexity/llama-3.1-sonar-large-128k-online
Available Model Group Fallbacks=None

### llama-3.1-sonar-small-128k-online(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for perplexity/llama-3.1-sonar-small-128k-online.","code":404},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/perplexity/llama-3.1-sonar-small-128k-online
Available Model Group Fallbacks=None

### o1-preview(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"Provider returned error","code":404,"metadata":{"raw":"{\n    \"error\": {\n        \"message\": \"The model `o1-preview` does not exist or you do not have access to it.\",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": \"model_not_found\"\n    }\n}\n","provider_name":"OpenAI"}},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/openai/o1-preview
Available Model Group Fallbacks=None

### o1-preview-2024-09-12(clinesp)
Error: Status 404: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"Provider returned error","code":404,"metadata":{"raw":"{\n    \"error\": {\n        \"message\": \"The model `o1-preview-2024-09-12` does not exist or you do not have access to it.\",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": \"model_not_found\"\n    }\n}\n","provider_name":"OpenAI"}},"user_id":"user_2dvySw1JqTZzABYD4OncxXptEmq"}. Received Model Group=blackboxai/openai/o1-preview-2024-09-12
Available Model Group Fallbacks=None

### playai-tts
Error: Status 400: unknown field `messages` in request body

### provider10-claude-sonnet-4-20250514(clinesp)
Error: Status 500: Provider error: SciraChat request failed: Failed to generate response - (401, Unauthorized) - {"code":"unauthorized:model","message":"You need to sign in to access this AI model.","cause":"Authentication required to access scira-anthropic"}

### provider10-deepseek-v3-0324(clinesp)
Error: Status 500: Provider error: SciraChat request failed: Failed to generate response - (401, Unauthorized) - {"code":"unauthorized:model","message":"You need to sign in to access this AI model.","cause":"scira-deepseek-v3 requires authentication"}

### provider10-gemini-2.5-flash(clinesp)
Error: Status 500: Provider error: SciraChat request failed: Failed to generate response - (401, Unauthorized) - {"code":"unauthorized:model","message":"You need to sign in to access this AI model.","cause":"Authentication required to access scira-google"}

### provider10-gemini-2.5-flash-lite-preview-06-17(clinesp)
Error: Status 500: Provider error: SciraChat request failed: Failed to generate response - (401, Unauthorized) - {"code":"unauthorized:model","message":"You need to sign in to access this AI model.","cause":"scira-google-lite requires authentication"}

### provider10-grok-3(clinesp)
Error: Status 500: Provider error: SciraChat request failed: Failed to generate response - (401, Unauthorized) - {"code":"unauthorized:model","message":"You need to sign in to access this AI model.","cause":"scira-grok-3 requires authentication"}

### provider10-grok-4(clinesp)
Error: Status 500: Provider error: SciraChat request failed: Failed to generate response - (401, Unauthorized) - {"code":"unauthorized:model","message":"You need to sign in to access this AI model.","cause":"scira-grok-4 requires authentication"}

### provider11-Kimi/k1.5
Error: Status 500: Provider error: Kimi request failed: HTTP Error 400: 

### provider11-Kimi/k1.5-thinking
Error: Status 500: Provider error: Kimi request failed: HTTP Error 400: 

### provider11-Kimi/k2
Error: Status 500: Provider error: Kimi request failed: HTTP Error 400: 

### provider2-claude-3.5-haiku(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider2-deepseek-chat(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider2-deepseek-reasoner(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider2-gemini-2.0-flash(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider2-gemini-2.5-flash(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider2-gpt-4.1-mini(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider2-grok-3-mini(clinesp)
Error: Status 500: Provider error: Flowith request failed: 429 Client Error: Too Many Requests for url: https://edge.flowith.net/ai/chat?mode=general

### provider4-deepseek-r1-distill-qwen-32b
Error: Status 500: Provider error: ExaChat request failed: 500 Server Error: Internal Server Error for url: https://ayle.chat/api/groq

### provider4-grok-3-mini-beta
Error: Status 500: Provider error: ExaChat request failed: 400 Client Error: Bad Request for url: https://ayle.chat/api/xai

### provider4-qwen-2.5-coder-32b
Error: Status 500: Provider error: ExaChat request failed: 500 Server Error: Internal Server Error for url: https://ayle.chat/api/groq

### provider5-anthropic/claude-3-7-sonnet-latest(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-anthropic/claude-4-opus(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-anthropic/claude-4-sonnet(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-Prover-V2-671B(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-R1(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-R1-0528(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-R1-0528-Turbo(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-R1-Turbo(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-V3(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-V3-0324(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-deepseek-ai/DeepSeek-V3-0324-Turbo(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-google/gemini-2.0-flash-001(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-google/gemini-2.5-flash(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-google/gemini-2.5-pro(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-moonshotai/Kimi-K2-Instruct(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-NovaSky-AI/Sky-T1-32B-Preview(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen2.5-72B-Instruct(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen2.5-Coder-32B-Instruct(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-14B(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-235B-A22B(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-235B-A22B-Instruct-2507
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-235B-A22B-Thinking-2507(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-30B-A3B(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-32B(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-Coder-480B-A35B-Instruct
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-Qwen/QwQ-32B(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-zai-org/GLM-4.5(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider5-zai-org/GLM-4.5-Air(clinesp)
Error: Status 500: Provider error: DeepInfra request failed: 403 Client Error: Forbidden for url: https://api.deepinfra.com/v1/openai/chat/completions

### provider6-Copilot
Error: Error: HTTPSConnectionPool(host='samuraiapi.in', port=443): Read timed out. (read timeout=30)

### provider6-Think Deeper
Error: Error: HTTPSConnectionPool(host='samuraiapi.in', port=443): Read timed out. (read timeout=30)

### provider7-anthropic/claude-sonnet-4-20250514(clinesp)
Error: Error: HTTPSConnectionPool(host='samuraiapi.in', port=443): Read timed out. (read timeout=30)

### provider9-grok-2-1212
Error: Status 500: Provider error: Toolbaz request failed: 400 Client Error: Bad Request for url: https://data.toolbaz.com/writing.php

### provider9-grok-3-beta
Error: Status 500: Provider error: Toolbaz request failed: 400 Client Error: Bad Request for url: https://data.toolbaz.com/writing.php

### provider9-sonar
Error: Status 500: Provider error: Toolbaz request failed: 400 Client Error: Bad Request for url: https://data.toolbaz.com/writing.php

### Samurai-Hosted/Qwen3-Embedding-8B
Error: Status 422: 

### Samurai-hs/Qwen3-235B-A22B-Instruct-2507
Error: Status 404: 
